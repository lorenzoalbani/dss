{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef0a8479",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "138c92d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La tua API Key\n",
    "API_KEY = \"AIzaSyA9BMJiGhlfOT7uTsskle7Rc_YcClbxWmM\"\n",
    "\n",
    "# Crea il client YouTube\n",
    "youtube = build('youtube', 'v3', developerKey=API_KEY)\n",
    "\n",
    "def get_video_statistics_batch(video_ids):\n",
    "    \"\"\"\n",
    "    Recupera statistiche per fino a 50 video ID in una singola chiamata API.\n",
    "    Ritorna un dizionario con video_id come chiave.\n",
    "    \"\"\"\n",
    "    # YouTube API accetta max 50 IDs per chiamata\n",
    "    video_ids_str = ','.join(video_ids)\n",
    "    \n",
    "    try:\n",
    "        request = youtube.videos().list(\n",
    "            part='statistics,contentDetails,snippet',\n",
    "            id=video_ids_str\n",
    "        )\n",
    "        response = request.execute()\n",
    "        \n",
    "        stats_dict = {}\n",
    "        \n",
    "        for item in response.get('items', []):\n",
    "            video_id = item['id']\n",
    "            stats = item.get('statistics', {})\n",
    "            content_details = item.get('contentDetails', {})\n",
    "            snippet = item.get('snippet', {})\n",
    "            \n",
    "            stats_dict[video_id] = {\n",
    "                'view_count': int(stats.get('viewCount', 0)),\n",
    "                'like_count': int(stats.get('likeCount', 0)),\n",
    "                'comment_count': int(stats.get('commentCount', 0)),\n",
    "                'duration': content_details.get('duration', None),\n",
    "                'definition': content_details.get('definition', None),\n",
    "                'published_at': snippet.get('publishedAt', None),\n",
    "                'category_id': snippet.get('categoryId', None)\n",
    "            }\n",
    "        \n",
    "        return stats_dict\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Errore nel recupero batch: {e}\")\n",
    "        return {}\n",
    "\n",
    "def enrich_with_youtube_statistics(df, video_id_col='youtube_video_id', \n",
    "                                   batch_size=50, output_file='youtube_stats_enriched.csv'):\n",
    "    \"\"\"\n",
    "    Arricchisce il dataframe con statistiche YouTube usando batch API calls.\n",
    "    \"\"\"\n",
    "    # Filtra solo le righe con video ID validi\n",
    "    df_with_ids = df[df[video_id_col].notna()].copy()\n",
    "    video_ids_list = df_with_ids[video_id_col].tolist()\n",
    "    \n",
    "    print(f\"Totale video ID da processare: {len(video_ids_list)}\")\n",
    "    print(f\"Batch da {batch_size} video per chiamata API\")\n",
    "    print(f\"Chiamate API necessarie: {len(video_ids_list) // batch_size + 1}\")\n",
    "    print(f\"Quota consumata stimata: ~{len(video_ids_list) // batch_size + 1} units\\n\")\n",
    "    \n",
    "    # Inizializza nuove colonne\n",
    "    df['yt_view_count'] = None\n",
    "    df['yt_like_count'] = None\n",
    "    df['yt_comment_count'] = None\n",
    "    df['yt_duration'] = None\n",
    "    df['yt_definition'] = None\n",
    "    df['yt_published_at'] = None\n",
    "    df['yt_category_id'] = None\n",
    "    \n",
    "    # Processa in batch\n",
    "    all_stats = {}\n",
    "    \n",
    "    for i in tqdm(range(0, len(video_ids_list), batch_size), \n",
    "                  desc=\"Recupero statistiche YouTube\", \n",
    "                  unit=\"batch\",\n",
    "                  colour=\"blue\"):\n",
    "        \n",
    "        batch = video_ids_list[i:i+batch_size]\n",
    "        batch_stats = get_video_statistics_batch(batch)\n",
    "        all_stats.update(batch_stats)\n",
    "        \n",
    "        # Piccola pausa per rispettare rate limits (opzionale ma consigliato)\n",
    "        time.sleep(0.2)\n",
    "    \n",
    "    print(f\"\\n✓ Recuperate statistiche per {len(all_stats)} video su {len(video_ids_list)}\")\n",
    "    \n",
    "    # Mappa le statistiche sul dataframe\n",
    "    for col_name, stat_key in [\n",
    "        ('yt_view_count', 'view_count'),\n",
    "        ('yt_like_count', 'like_count'),\n",
    "        ('yt_comment_count', 'comment_count'),\n",
    "        ('yt_duration', 'duration'),\n",
    "        ('yt_definition', 'definition'),\n",
    "        ('yt_published_at', 'published_at'),\n",
    "        ('yt_category_id', 'category_id')\n",
    "    ]:\n",
    "        df[col_name] = df[video_id_col].map(\n",
    "            lambda vid: all_stats.get(vid, {}).get(stat_key, None) if pd.notna(vid) else None\n",
    "        )\n",
    "    \n",
    "    # Salva il risultato\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"\\n✓ Dataset arricchito salvato in: {output_file}\")\n",
    "    \n",
    "    # Statistiche finali\n",
    "    print(f\"\\nStatistiche recupero:\")\n",
    "    print(f\"  - View count trovati: {df['yt_view_count'].notna().sum()}/{len(df)}\")\n",
    "    print(f\"  - Like count trovati: {df['yt_like_count'].notna().sum()}/{len(df)}\")\n",
    "    print(f\"  - Comment count trovati: {df['yt_comment_count'].notna().sum()}/{len(df)}\")\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecc0f0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totale video ID da processare: 11142\n",
      "Batch da 50 video per chiamata API\n",
      "Chiamate API necessarie: 223\n",
      "Quota consumata stimata: ~223 units\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recupero statistiche YouTube: 100%|\u001b[34m██████████\u001b[0m| 223/223 [02:06<00:00,  1.76batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Recuperate statistiche per 10453 video su 11142\n",
      "\n",
      "✓ Dataset arricchito salvato in: songs_with_youtube_stats.csv\n",
      "\n",
      "Statistiche recupero:\n",
      "  - View count trovati: 11135/11166\n",
      "  - Like count trovati: 11135/11166\n",
      "  - Comment count trovati: 11135/11166\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Carica il dataframe con gli ID scrapati\n",
    "df = pd.read_csv('songs_with_youtube_ids.csv')  # o il tuo file con gli ID\n",
    "\n",
    "# 2. Arricchisci con le statistiche YouTube\n",
    "df_enriched = enrich_with_youtube_statistics(\n",
    "    df, \n",
    "    video_id_col='youtube_video_id',\n",
    "    batch_size=50,\n",
    "    output_file='songs_with_youtube_stats.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15f76ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
